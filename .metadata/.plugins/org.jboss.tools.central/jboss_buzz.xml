<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title>Containers and container images 101 for developers</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/08/29/containers-and-container-images-101-developers" /><author><name>Don Schenck</name></author><id>eaeb35d4-6a27-4010-9260-ae0102993164</id><updated>2022-08-29T07:00:00Z</updated><published>2022-08-29T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/topics/containers"&gt;Containers&lt;/a&gt;, &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/topics/microservices"&gt;microservices&lt;/a&gt; have been a hot topic for the past few years, yet many developers may still be wondering how they all work. To take a somewhat different angle on the subject, this article will describe how a container image is constructed and executed using a non-traditional, conversational approach.&lt;/p&gt; &lt;p&gt;First, let's take a quick look at the layers of a container image and how they relate to one another.&lt;/p&gt; &lt;h2&gt;What is a container image?&lt;/h2&gt; &lt;p&gt;Briefly, an &lt;em&gt;image&lt;/em&gt; is an operating system that runs libraries and runtimes and an application, all enclosed in an &lt;a href="https://opencontainers.org/"&gt;Open Container Initiative&lt;/a&gt; (OCI) compliant file.&lt;/p&gt; &lt;p&gt;Figure 1 illustrates an example: a &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js&lt;/a&gt; application that uses the Express library, running on the &lt;a href="https://developers.redhat.com/products/rhel/ubi"&gt;Red Hat Universal Base Image&lt;/a&gt; (UBI) operating system. If you're not familiar with Express, it's (as their &lt;a href="https://expressjs.com/"&gt;website&lt;/a&gt; says) a "fast, unopinionated, minimalist web framework for Node.js" that makes it easy to create a Web API (RESTful) service.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt; &lt;img alt="Image illustrating layers of a Linux image running a Node.js application" data-entity-type="file" data-entity-uuid="3b68b583-b28a-4c81-827a-9ba8a811783c" src="https://developers.redhat.com/sites/default/files/inline-images/node%20app%20on%20ubi_0.png" width="960" height="531" loading="lazy" /&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: Layers of a Linux image running a Node.js application&lt;/figcaption&gt; &lt;/figure&gt; &lt;h2&gt;How containers work&lt;/h2&gt; &lt;p&gt;If running a container were a conversation between all the interested parties, it would go something like this:&lt;/p&gt; &lt;table border="1" cellpadding="1" cellspacing="1" width="500"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th scope="col"&gt;Actor&lt;/th&gt; &lt;th scope="col"&gt;Dialog&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;Command line:&lt;/p&gt; &lt;p&gt;&lt;code&gt;docker run&lt;/code&gt;...&lt;/p&gt; &lt;p&gt;or&lt;/p&gt; &lt;p&gt;&lt;code&gt;podman run&lt;/code&gt;...&lt;/p&gt; &lt;/td&gt; &lt;td&gt;"Hey Docker/Podman machine, run this image with these parameters. Thanks."&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Machine&lt;/td&gt; &lt;td&gt; &lt;p&gt;"Sure."&lt;/p&gt; &lt;p&gt;(Checks the registries in the configured list of registries to find the image to run. If the image isn't located in a local registry, it will pull from a remote registry.)&lt;/p&gt; &lt;p&gt;"Got the image. I'll now inspect the OCI-compliant interface; I need some information to run this image. I need..."&lt;/p&gt; &lt;ul&gt; &lt;li&gt;A user under which to run, e.g., &lt;code&gt;root&lt;/code&gt;&lt;/li&gt; &lt;li&gt;The command needed to start the image.&lt;/li&gt; &lt;li&gt;The ports that should be exposed.&lt;/li&gt; &lt;li&gt;Environment variables and values&lt;/li&gt; &lt;li&gt;...and more.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;"OK, I have everything I need. Now the host operating system kernel needs to start running this image in a container."&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Container (after being started by machine)&lt;/td&gt; &lt;td&gt; &lt;p&gt;"Hello Linux (or Windows) kernel! Hope you're well today. Say ... I need access to a TCP port so I can process traffic in and out."&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Host OS kernel&lt;/td&gt; &lt;td&gt;"No problem. Here's a list of open ports."&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Machine&lt;/td&gt; &lt;td&gt;"I'm gonna choose this one and use it for this container. But since a port was specified on the command line to start this container, I'll redirect to that port for the container."&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Container&lt;/td&gt; &lt;td&gt;"Awesome; I'm processing traffic on the port of my choosing. Life is good."&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Learn more about containers&lt;/h2&gt; &lt;p&gt;I hope this unique take on how a container works is helpful. If you want more information, check out the links I've listed below. If you want to actually build and use containers, take advantage of the &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt;, available at no cost.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/topics/containers"&gt;Red Hat Developers containers topic page&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/cheat-sheets/containers-old"&gt;Containers Cheat Sheet&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/16/how-convert-web-application-software-service"&gt;How to convert a web application to Software-as-a-Service&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/08/29/containers-and-container-images-101-developers" title="Containers and container images 101 for developers"&gt;Containers and container images 101 for developers&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Don Schenck</dc:creator><dc:date>2022-08-29T07:00:00Z</dc:date></entry><entry><title type="html">Testing with Awaitility made simple</title><link rel="alternate" href="http://www.mastertheboss.com/various-stuff/testing-java/testing-with-awaitility-made-simple/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/various-stuff/testing-java/testing-with-awaitility-made-simple/</id><updated>2022-08-26T15:44:54Z</updated><content type="html">The Awaitility library introduces a functional style usage to express expectations of an asynchronous system in a concise and easy to read manner. Let’s have a deep dive into it with this tutorial. Overview of Awaitility Awaitility (as the name says) checks expectations based on a timing condition. Here is a basic example of it: ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">Deploying DashBuilder client on OpenShift Developer Sandbox</title><link rel="alternate" href="https://blog.kie.org/2022/08/deploying-dashbuilder-client-on-openshift-developer-sandbox.html" /><author><name>Manaswini Das</name></author><id>https://blog.kie.org/2022/08/deploying-dashbuilder-client-on-openshift-developer-sandbox.html</id><updated>2022-08-26T11:24:23Z</updated><content type="html">This blog post is going to walk you through building and running a custom Nginx Docker image for a sample DashBuilder static application to be deployed on OpenShift Developer Sandbox. DashBuilder has a client bundle, which consists of the DashBuilder Webapp. The deployment is simply modifying setup.js to include user dashboards and then serving index.html. In case you already have an image ready to deploy/publish on OpenShift Developer Sandbox, you can skip to the last section of this blog post. You can also use my image . CREATING A CUSTOM NGINX DOCKER IMAGE Normally, using Nginx with Docker, we would not Nginx from the official image and then configure it manually. We will use the pre-configured Nginx Docker Image and all we need to do is start the container from those Nginx Docker images and use them. In order to get started, we have to unpack an which contains the sample DashBuilder static application. Create a new folder and install the NPM package. mkdir newfolder cd newfolder npm i @kie-tools/dashbuilder-client Now we can get some sample YAML dashboards from and copy them into the dist folder inside node_modules/@kie-tools/dashbuilder-client. Now we also have to tweak setup.js to include the dashboards. Just add dashboards: [“sample.dash.yml”] inside the dashbuilder object inside setup.js. You can choose to add multiple dashboards too. Just add them as comma-separated strings in dashboards inside the dashbuilder object inside setup.js. In order to create an image, we need to know how an Nginx Docker image can be created. By default, Nginx looks in the /usr/share/nginx/html directory inside of the container for files to serve. We need to get our static files into this directory. One of the simplest ways to do this is to copy our HTML files into the image by building a custom image. To build a custom image, we’ll need to create a Dockerfile and add our commands to it. In the newfolder directory which now contains the node_modules folder, create a file named Dockerfile and paste the below commands. FROM nginxinc/nginx-unprivileged COPY /node_modules/@kie-tools/dashbuilder-client/dist/ /usr/share/nginx/html/ &gt; Note: We are using the since Openshift has limited permissions for Nginx and &gt; we may face errors like Openshift Nginx permission problem [nginx: [emerg] &gt; mkdir() “/var/cache/nginx/client_temp” failed (13: Permission denied)] while &gt; deploying our image to Openshift Developer Sandbox. So, it’s necessary to run &gt; Nginx as a non-root user. Refer to the “Running Nginx as a non-root user” &gt; section of for more information. We start building our custom image by using a base image. The FROM command will pull the nginxinc/nginx-unprivileged image to our local machine and then build our custom image on top of it. Next, we the contents of the folder containing the static content into the /usr/share/nginx/html directory inside the container overwriting the default index.html file provided by nginxinc/nginx-unprivileged image. You’ll notice that we did not add an ENTRYPOINT or a CMD to our Dockerfile. We will use the underlying ENTRYPOINT and CMD provided by the base Nginx image. Make sure you have in your system. Once you have Docker installed in your system, start Docker using the following command. You can also use for the same: sudo service docker start &gt; Troubleshooting &gt; &gt; Fresh install Docker cgroup mountpoint does not exist. Just run the following &gt; command or refer to : &gt; &gt; sudo mkdir /sys/fs/cgroup/systemd &gt; sudo mount -t cgroup -o none,name=systemd cgroup /sys/fs/cgroup/systemd We now need to run the following command on a terminal inside the newfolder directory. docker build -f Dockerfile -t dashbuilder . You will see the following on your terminal on the successful execution of the above statement. Note: Don’t forget to add the . at the end else you might get error like: ”docker build” requires exactly 1 argument. See ‘docker build — help’. Usage: docker build [OPTIONS] PATH | URL | - Build an image from a Dockerfile Time to run the image. To run the image, run the following command: docker run -it — rm -d -p 8080:80 — name web dashbuilder web is the container name and dashbuilder is the image name. Standard practice is to name your containers for the simple reason that it is easier to identify what is running in the container and what application or service it is associated with. Just like good naming conventions for variables in your code makes it simpler to read. So goes naming your containers. To name a container, we must pass the — name flag to the run command. Open your browser and navigate to to make sure our HTML page is being served correctly. This is what you will see on your browser. Served index.html containing sample dashboard SHIPPING YOUR IMAGE It’s time to publish the image on an image registry so that we can later deploy it in OpenShift Developer Sandbox. I’m using Docker Hub. You can and receive free unlimited public repositories. You can also use . Sharing our images on will help others on our team pull the images and run them locally. This is also a great way to share your application with others outside of your teams such as testers and business owners. To push your images to Docker’s repository run the docker tag and then the docker push commands. You will first need to log in with your Docker ID. $ docker login $ docker tag dashbuilder &lt;dockerid&gt;/dashbuilder $ docker push &lt;dockerid&gt;/dashbuilder Check whether you see the following output on your terminal on successful execution. You will be able to see your repository on your Docker Hub account. Docker Hub repositories page now contains your image DEPLOY IMAGE ON OPENSHIFT DEVELOPER SANDBOX Refer to to set up and start your OpenShift Developer Sandbox for free. Once you start using your sandbox, you can either use the CLI or the GUI to publish/deploy your image. In case you are comfortable with using CLI, you can refer to to deploy and expose your application. Alternatively, you can use the GUI to deploy your image. Click on the Hamburger button on the top left and click on the “+Add” button. You will see the following screen. Add menu in OpenShift Developer Sandbox Select “Container Images” and start filling the Deploy image form as follows. Page 1 of 2 of Deploy Image Page 2 of Deploy Image Now click on “Create”. This will immediately take you to the page corresponding to the Topology tab on your right menu. Topology view Click on the same and navigate to the “Resources” tab and you will be able to see a link in the “Routes” section. Click on the link and see your application running on another tab. Routes section in Resources tab DashBuilder static application running on OpenShift Developer Sandbox Great! You can now create an Nginx Docker image and deploy the image on OpenShift Developer Sandbox. Let us know whether you were able to get your DashBuilder static application to run successfully. The post appeared first on .</content><dc:creator>Manaswini Das</dc:creator></entry><entry><title type="html">Kogito 1.26.0 released!</title><link rel="alternate" href="https://blog.kie.org/2022/08/kogito-1-26-0-released.html" /><author><name>Cristiano Nicolai</name></author><id>https://blog.kie.org/2022/08/kogito-1-26-0-released.html</id><updated>2022-08-26T03:00:57Z</updated><content type="html">We are glad to announce that the Kogito 1.26.0 release is now available! This goes hand in hand with , release. From a feature point of view, we have included a series of new features and bug fixes, including: * Default value for enumerations in GRPC is included in response if property kogito.grpc.enum.includeDefault is set to true * Changing rejection handler policy for event executor thread. Rather than executing task in the same thread (which might lead to blocking exception), the emitter is stopped while the executor service is full * Avoiding creation of unneeded process instances when workflow json input schema validation fails.  For more details head to the complete . All artifacts are available now: * Kogito runtime artifacts are available on Maven Central. * Kogito examples can be found . * Kogito images are available on . * Kogito operator is available in the in OpenShift and Kubernetes. * Kogito tooling 0.22.0 artifacts are available at the . A detailed changelog for 1.26.0 can be found in . New to Kogito? Check out our website . Click the "Get Started" button. The post appeared first on .</content><dc:creator>Cristiano Nicolai</dc:creator></entry><entry><title type="html">Quarkus Tools for IntelliJ 1.12.0 released!</title><link rel="alternate" href="https://quarkus.io/blog/intellij-quarkus-tools-1.12.0/" /><author><name>Jeff Maury</name></author><id>https://quarkus.io/blog/intellij-quarkus-tools-1.12.0/</id><updated>2022-08-26T00:00:00Z</updated><content type="html">We are very pleased to announce the 1.12.0 release of Quarkus Tools for IntelliJ. This release improves the Quarkus wizard and Quarkus run experience but also aligns with LSP4MP 0.5.0 and quarkus-ls 0.12.1. Improved Quarkus wizard The Quarkus wizard can be used from File → New → Module → Quarkus....</content><dc:creator>Jeff Maury</dc:creator></entry><entry><title>Optimize loops with long variables in Java</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/08/25/optimize-loops-long-variables-java" /><author><name>Roland Westrelin</name></author><id>7ff3d707-eeb0-4375-b621-eb93c88316fa</id><updated>2022-08-25T07:00:00Z</updated><published>2022-08-25T07:00:00Z</published><summary type="html">&lt;p&gt;The &lt;a href="https://developers.redhat.com/articles/2021/06/23/how-jit-compiler-boosts-java-performance-openjdk"&gt;just-in-time (JIT) compiler&lt;/a&gt; in &lt;a href="https://openjdk.org"&gt;OpenJDK&lt;/a&gt; improves &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; performance through a number of optimizations, particularly in loops. Until recently, many optimizations worked only when the loop index was an &lt;code&gt;int&lt;/code&gt; variable. This article shows how the &lt;a href="https://openjdk.org/groups/hotspot"&gt;HotSpot virtual machine&lt;/a&gt; was upgraded to add the same optimizations for &lt;code&gt;long&lt;/code&gt; variables. The article covers particularly out-of-bounds checking (also called &lt;em&gt;range checks&lt;/em&gt;).&lt;/p&gt; &lt;h2&gt;Why optimization was added for long variables&lt;/h2&gt; &lt;p&gt;One of the important promises of Java, along with many other modern languages, is to catch out-of-bounds errors, such as when you mistakenly end a loop at &lt;code&gt;array.length&lt;/code&gt; instead of at &lt;code&gt;array.length-1&lt;/code&gt;. The HotSpot virtual machine eliminates range checks when possible as a performance optimization. As discussed in a &lt;a href="https://developers.redhat.com/articles/2022/03/16/range-check-elimination-loops-openjdks-hotspot-jvm"&gt;previous article&lt;/a&gt;, the JIT compiler enables range checks when the compiler is not sure that an index will stay within the bounds of an array.&lt;/p&gt; &lt;p&gt;The JIT compiler implements range checks as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;for (int i = start; i &lt; stop; i += stride)) { if (scale * i + offset &gt;=u array.length) { // range check deoptimize(); } // access to element scale * i + offset of array }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In the previous code, &lt;code&gt;&gt;=u&lt;/code&gt; is an unsigned comparison, and the &lt;code&gt;deoptimize()&lt;/code&gt; function causes execution of the thread to continue in the interpreter where the out of bound exception is thrown.&lt;/p&gt; &lt;p&gt;Until recent versions of OpenJDK, optimization of range checks worked only if the loop variable &lt;code&gt;i&lt;/code&gt; was an &lt;code&gt;int&lt;/code&gt;. For a &lt;code&gt;long&lt;/code&gt;, range checks would always be performed. Many other optimizations were also unavailable.&lt;/p&gt; &lt;p&gt;The reason for restricting loop optimization to &lt;code&gt;int&lt;/code&gt; indexes was that they were considered the only ones common enough to deserve special treatment. One reason is that loops commonly iterate over arrays. Because the size of a Java array is a 32-bit integer, an &lt;code&gt;int&lt;/code&gt; is the natural choice for the loop variable.&lt;/p&gt; &lt;p&gt;Usages are evolving, though. The &lt;a href="https://openjdk.org/projects/panama/"&gt;Panama Project&lt;/a&gt; offers developers a better way to get access to off-heap memory areas. Offsets within memory are 64 bits, so loops that iterate over memory with that API tend to use a &lt;code&gt;long&lt;/code&gt; loop variable.&lt;/p&gt; &lt;p&gt;The lack of proper optimizations for &lt;code&gt;long&lt;/code&gt; counted loops initially was such a pain point for the Panama Project that it implemented workarounds in the library code to detect cases where the offsets fit into a 32-bit integer. In such cases, the project included special code that the JIT could better optimize. But once the improvements covered in this article were rolled out, those workarounds became unnecessary and could be removed. The end result is simplified library code with better overall performance.&lt;/p&gt; &lt;p&gt;The loop shape that needs to be optimized is as follows:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;for (long i = start; i &lt; stop; i += stride)) { if (scale * i + offset &gt;=u length) { // range check deoptimize(); } // access to memory at offset scale * i + offset }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The discussion in this article assumes a loop that goes upward (that is, an index that increases), along with a positive &lt;code&gt;scale&lt;/code&gt;. The project has generalized the optimization to accommodate a decreasing loop and a negative &lt;code&gt;scale&lt;/code&gt; as well, but we won't include those cases because they would overcomplicate the discussion.&lt;/p&gt; &lt;h2&gt;Recognizing and optimizing long counted loops&lt;/h2&gt; &lt;p&gt;Teaching the compiler to recognize the new loop shape with a &lt;code&gt;long&lt;/code&gt; loop variable instead of an &lt;code&gt;int&lt;/code&gt; loop variable is fairly straightforward, but is not sufficient to enable existing optimizations such as range check elimination, loop unrolling, and vectorization. Those optimization passes must be adapted to operate on a &lt;code&gt;long&lt;/code&gt; counted loop as well. Doing so is not a simple matter of including &lt;code&gt;long&lt;/code&gt; variables, because some of the optimizations have to deal with integer overflow. They were protected from overflow for &lt;code&gt;int&lt;/code&gt; variables by promoting some 32-bit integer values to 64-bit integers. Supporting these same optimizations on 64-bit integers would require promotion to the next larger integer type (probably 128 bits), for which the compiler lacks support.&lt;/p&gt; &lt;p&gt;Is there a way to upgrade the existing optimizations for a &lt;code&gt;long&lt;/code&gt; without having to rewrite these optimizations and incur a high risk of introducing bugs?&lt;/p&gt; &lt;p&gt;The solution we went with started by transforming the &lt;code&gt;long&lt;/code&gt; counted loop into a nested loop with an &lt;code&gt;int&lt;/code&gt; counted inner loop. The previous example was transformed roughly to:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;for (long i = start; i &lt; stop;) { int j; for (j = 0; j &lt; min(stop - i, max_int); j += (int)stride) { if (scale * (j + i) + offset &gt;=u length) { // range check deoptimize(); } // access to memory at offset scale * (j+i) + offset } i += j; }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Here, &lt;code&gt;max_int&lt;/code&gt; represents the largest signed 32-bit integer. The loop variable for the inner loop is also a 32-bit integer. That inner loop has the shape of a counted loop, so it's subject to existing counted loop optimizations such as unrolling. Adding an extra loop has some overhead, but if the original loop executes for a large number of iterations, most of the time should be spent in the inner loop and the cost of setting it up should be negligible.&lt;/p&gt; &lt;p&gt;Note that this transformation is valid only for &lt;code&gt;stride&lt;/code&gt; values that fit into a 32-bit integer, and pays off mostly if &lt;code&gt;stride&lt;/code&gt; is a relatively small 32-bit integer. (Otherwise, the inner loop executes only a small number of iterations and the overhead of nested loops is bigger.)&lt;/p&gt; &lt;p&gt;This extra transformation has the benefit of enabling several existing loop optimizations to &lt;code&gt;long&lt;/code&gt; loop counters. But one important optimization still isn't triggered by the transformed loop: Eliminating the range check. Indeed, the range check in the previous loop nest is still expressed in terms of 64-bit integers: &lt;code&gt;j+i&lt;/code&gt; and &lt;code&gt;length&lt;/code&gt;. The next section discusses how we make sure the range check has a proper shape so that the compiler recognizes it and enables range check optimization.&lt;/p&gt; &lt;h2&gt;A new API point for range checks&lt;/h2&gt; &lt;p&gt;A prerequisite for range check elimination is to make sure the loop has a shape that the compiler can properly optimize. In particular, the range check in the loop has to follow a canonical shape like the following, with an unsigned comparison and a deoptimization if the range check fails:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;if (scale * i + offset &gt;=u length) { deoptimize(); }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The array accesses in Java include a range check, so the compiler is free to generate the pattern that works best for optimization. In the Panama Project's memory access API, the range check is not built into the language. So the check would have to be performed explicitly by the API in code similar to:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;long o = scale * i + offset; if (o &gt;= length || o &lt; 0) { throw new SomeException(); }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The JIT compiler would then have to recognize this code pattern as a range check, which would be complicated to perform reliably. After all, there would be more than one way to write this logic.&lt;/p&gt; &lt;p&gt;We have a more robust solution, which involves extending the core Java libraries with a new API point for range checks:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;long o = java.util.Objects.checkIndex(scale * i + offset, length);&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;checkIndex()&lt;/code&gt; call already exists for &lt;code&gt;int&lt;/code&gt; arguments.&lt;/p&gt; &lt;p&gt;We have made the JIT compiler aware of the new API function. The compiler can use its own implementation for &lt;code&gt;checkIndex()&lt;/code&gt; as long as its behavior appears identical to the Java implementation to outside callers.&lt;/p&gt; &lt;p&gt;The technique of replacing a standard implementation of a function with one provided by the compiler is called a &lt;em&gt;compiler intrinsic&lt;/em&gt;. That implementation can be carefully crafted to allow optimizations.&lt;/p&gt; &lt;p&gt;The new &lt;code&gt;checkIndex()&lt;/code&gt; function and the corresponding underlying intrinsic are &lt;a href="https://github.com/openjdk/jdk/pull/1003"&gt;available as of JDK 16&lt;/a&gt;. Note that the new function is not restricted to the memory access API. It offers a reliable way of performing range checks that can be optimized well by the virtual machine, making the function a valuable addition to the core libraries for all developers.&lt;/p&gt; &lt;h2&gt;Optimizing long-range checks&lt;/h2&gt; &lt;p&gt;So far, we have discussed a transformation of the loop so that it becomes suitable for existing optimizations. In the same spirit, this section discusses how to transform range checks in order to trigger existing range check optimizations for &lt;code&gt;long&lt;/code&gt; indexes. We need to reshape the nested loop to:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;for (long i = start; i &lt; stop;) { int j; int scale' = ..; int offset' = ..; int length' = ..; for (j = 0; j &lt; min(stop - i, max_int); j += (int)stride) { if (scale' * j + offset' &gt;=u length') { deoptimize(); } // access to memory at offset scale * (j+i) + offset } i += j; }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;scale'&lt;/code&gt;, &lt;code&gt;offset'&lt;/code&gt;, and &lt;code&gt;length'&lt;/code&gt; variables end with a prime symbol (&lt;code&gt;'&lt;/code&gt;) to denote a variable that is derived from or related to another variable. These variables are 32-bit integers that are invariant in the inner loop. Because the range check is expressed as a 32-bit comparison that operates on the loop variable of the inner loop, which is itself a loop with a 32-bit index, existing optimizations are triggered.&lt;/p&gt; &lt;p&gt;Assuming for instance that loop predication optimizes this loop nest, the result would be roughly:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;for (long i = start; i &lt; stop;) { int j; int scale' = ..; int offset' = ..; int length' = ..; if (scale' * 0 + offset' &gt;=u length') { deoptimize(); } if (scale' * jmax + offset' &gt;=u length') { deoptimize(); } for (j = 0; j &lt; min(stop - i, max_int); j += (int)stride) { // access to memory at offset scale * (j+i) + offset } i += j; }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;code&gt;jmax&lt;/code&gt; is the largest value &lt;code&gt;j&lt;/code&gt; takes in the inner loop for a particular iteration &lt;code&gt;i&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Assuming, as we did before, that the inner loop runs for a large number of iterations, the range check becomes essentially free.&lt;/p&gt; &lt;p&gt;&lt;code&gt;scale'&lt;/code&gt;, &lt;code&gt;offset'&lt;/code&gt;, and &lt;code&gt;length'&lt;/code&gt; have to be derivatives of &lt;code&gt;scale&lt;/code&gt;, &lt;code&gt;offset&lt;/code&gt;, &lt;code&gt;length&lt;/code&gt;, and &lt;code&gt;i&lt;/code&gt;, the variables of the initial range check. They are all 64-bit integers. Let's see how to compute them.&lt;/p&gt; &lt;p&gt;&lt;code&gt;scale'&lt;/code&gt; can be set to &lt;code&gt;scale&lt;/code&gt;, but only if it fits in a 32-bit integer. Otherwise, there's no way to transform the range check. Another tricky issue here is that &lt;code&gt;scale' * j&lt;/code&gt; could overflow the &lt;code&gt;int&lt;/code&gt; range. One easy way around that problem is to adjust the inner loop's bounds so that overflow never happens, such as:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;for (long i = start; i &lt; stop;) { int j; int scale' = scale; int offset' = ..; int length' = ..; for (j = 0; j &lt; min(stop - i, max_int / scale); j += (int)stride) { if (scale' * j + offset' &gt;=u length') { deoptimize(); } // access to memory at offset scale * (j+i) + offset } i += j; }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If &lt;code&gt;scale&lt;/code&gt; turns out to be a relatively large 32-bit integer, the number of iterations of the inner loop is small and this transformation is unlikely to pay off. The Panama Project expects a small &lt;code&gt;scale&lt;/code&gt;. Typically, this variable is the size of some basic data type.&lt;/p&gt; &lt;p&gt;Let's note the range of values of &lt;code&gt;j&lt;/code&gt; for some iteration &lt;code&gt;i&lt;/code&gt; of the outer loop as&lt;code&gt;[0, jmax]&lt;/code&gt;. Then &lt;code&gt;scale * (i + j) + offset&lt;/code&gt; is in the range&lt;code&gt;[scale * i + offset, scale * (i + jmax) + offset]&lt;/code&gt; (remember that this discussion assumes a positive &lt;code&gt;scale&lt;/code&gt;). Let's call that interval &lt;code&gt;[range_min, range_max]&lt;/code&gt;. It's then possible to express &lt;code&gt;offset'&lt;/code&gt; and &lt;code&gt;length'&lt;/code&gt; in terms of &lt;code&gt;range_min&lt;/code&gt; and &lt;code&gt;range_max&lt;/code&gt;. In the simplest case (&lt;code&gt;range_min &gt;= 0&lt;/code&gt;, no overflow), we set:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;offset' = 0&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;length' = max(range_min, min(length, range_max+1)) - range_min&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Let's see why that works as expected—that is, why the transformed range check (expressed with &lt;code&gt;j&lt;/code&gt;) succeeds whenever the initial range check (expressed with &lt;code&gt;i&lt;/code&gt;) succeeds, and fails when the initial check fails.&lt;/p&gt; &lt;p&gt;We know that &lt;code&gt;j&lt;/code&gt; falls within &lt;code&gt;[0, jmax]&lt;/code&gt;. Then &lt;code&gt;range&lt;/code&gt; has the value &lt;code&gt;scale * (i + j) + offset&lt;/code&gt; and &lt;code&gt;range'&lt;/code&gt; has the value &lt;code&gt;scale * j + offset'&lt;/code&gt;. Using variables we defined earlier, &lt;code&gt;range&lt;/code&gt; is in &lt;code&gt;[range_min, range_max]&lt;/code&gt; and &lt;code&gt;range = range' + range_min&lt;/code&gt;. What happens for various values of &lt;code&gt;length&lt;/code&gt;?&lt;/p&gt; &lt;h3&gt;When length is greater than range_max&lt;/h3&gt; &lt;p&gt;In this case, the range check always succeeds. &lt;code&gt;length'&lt;/code&gt; is &lt;code&gt;range_max+1 - range_min&lt;/code&gt;. The range check becomes:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;range' &lt;u range_max+1 - range_min&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This expression is always true because &lt;code&gt;range&lt;/code&gt; is within &lt;code&gt;[range_min, range_max]&lt;/code&gt; and so &lt;code&gt;range'&lt;/code&gt; is within &lt;code&gt;[0, range_max - range_min]&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;When length is less than range_min&lt;/h3&gt; &lt;p&gt;In this case, the range check always fails. &lt;code&gt;length'&lt;/code&gt; is &lt;code&gt;0&lt;/code&gt;. The range check becomes &lt;code&gt;range'&lt;u 0&lt;/code&gt;, which is always false (no unsigned value can be negative).&lt;/p&gt; &lt;h3&gt;When length is somewhere in [range_min, range_max]&lt;/h3&gt; &lt;p&gt;If &lt;code&gt;length&lt;/code&gt; is in &lt;code&gt;[range_min, range_max]&lt;/code&gt;, the range check succeeds sometimes and fails other times. &lt;code&gt;length'&lt;/code&gt; is &lt;code&gt;length - range_min&lt;/code&gt;. The range check becomes:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;range' &lt;u length - range_min&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;which is equivalent to:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;0 &lt;= range' &lt; length - range_min &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;or&lt;/p&gt; &lt;pre&gt; &lt;code&gt;range_min &lt;= range' + range_min &lt; length &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;or&lt;/p&gt; &lt;pre&gt; &lt;code&gt;range_min &lt;= range &lt; length&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Because we assumed &lt;code&gt;range_min&lt;/code&gt; to be positive, this is the same as &lt;code&gt;range &lt;u length&lt;/code&gt;, the range check before transformation.&lt;/p&gt; &lt;p&gt;&lt;code&gt;length'&lt;/code&gt; must be a 32-bit integer, but is computed in terms of 64-bit values. Note, however, that &lt;code&gt;range_max - range_min&lt;/code&gt; fits in a 32-bit integer, because loop bounds require &lt;code&gt;scale * j&lt;/code&gt; to fit in a 32-bit integer. That, in turn, guarantees that &lt;code&gt;length'&lt;/code&gt; can safely be stored as a 32-bit value.&lt;/p&gt; &lt;h2&gt;Extensive optimizations accommodate more Java loops&lt;/h2&gt; &lt;p&gt;This article covered recent optimizations in the OpenJDK HotSpot virtual machine that support loops with &lt;code&gt;long&lt;/code&gt; loop variables, with a particular focus on range checks operating on it. I gave an overview of the code patterns that developers can expect to be properly optimized. The article also demonstrated how new APIs require special virtual machine support and how the entire Java platform evolves to meet changing usages. Finally, I showed how reshaping a loop with a &lt;code&gt;long&lt;/code&gt; index enables a range of optimizations.&lt;/p&gt; &lt;p&gt;The cases we didn't cover in this article—loops going downward and a negative &lt;code&gt;scale&lt;/code&gt;—are discussed in a &lt;a href="https://github.com/openjdk/jdk/blob/ef266d77b6eb54d7e30a0aafd8a3e8c8f4f0e43a/src/hotspot/share/opto/loopnode.cpp#L1150"&gt;lengthy comment&lt;/a&gt; added to the &lt;a href="https://github.com/openjdk/jdk/pull/2045"&gt;JDK change request&lt;/a&gt;, augmented by &lt;a href="https://github.com/openjdk/jdk/pull/6989"&gt;this follow-up&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/08/25/optimize-loops-long-variables-java" title="Optimize loops with long variables in Java"&gt;Optimize loops with long variables in Java&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Roland Westrelin</dc:creator><dc:date>2022-08-25T07:00:00Z</dc:date></entry><entry><title type="html">This Week in JBoss - 25 August 2022</title><link rel="alternate" href="https://www.jboss.org/posts/weekly-2022-08-25.html" /><category term="quarkus" /><category term="kubernetes" /><category term="java" /><category term="jakarta" /><category term="infinispan" /><category term="wildfly" /><category term="cloud-native" /><category term="openshift" /><category term="kogito" /><category term="drools" /><category term="keycloak" /><author><name>Pedro Silva</name><uri>https://www.jboss.org/people/pedro-silva</uri><email>do-not-reply@jboss.com</email></author><id>https://www.jboss.org/posts/weekly-2022-08-25.html</id><updated>2022-08-25T00:00:00Z</updated><content type="html">&lt;article class="" data-tags="quarkus, kubernetes, java, jakarta, infinispan, wildfly, cloud-native, openshift, kogito, drools, keycloak"&gt; &lt;h1&gt;This Week in JBoss - 25 August 2022&lt;/h1&gt; &lt;p class="preamble"&gt;&lt;/p&gt;&lt;p&gt;Hi everyone! It’s great to be back and bringing you another edition of the JBoss Editorial. As always there’s a lot of exciting news and updates from JBoss communities so let’s dive in.&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;div class="sect1"&gt; &lt;h2 id="_release_roundup"&gt;Release roundup&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist square"&gt; &lt;ul class="square"&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-2-11-3-final-released/"&gt;Quarkus 2.11.3.Final released - Fix for CVE-2022-2466 and other bugfixes&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_hola_你好_こんにちは_quarkus"&gt;Hola, 你好, こんにちは Quarkus&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/l10n-of-quarkusio/"&gt;Hola, 你好, こんにちは Quarkus&lt;/a&gt;, by Max Rydahl Andersen&lt;/p&gt; &lt;p&gt;Since the launch of Japanese &lt;a href="http://ja.quarkus.io/"&gt;ja.quarkus.io&lt;/a&gt;, we got contributors translating the website into (simplified) Chinese at &lt;a href="http://cn.quarkus.io"&gt;cn.quarkus.io&lt;/a&gt; and recently we added Spanish at &lt;a href="http://es.quarkus.io"&gt;es.quarkus.io&lt;/a&gt; too. These sites are now accessible via the drop-down "globe" menu in the top-right corner.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_using_rhosak_from_wildfly"&gt;Using RHOSAK from WildFly&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://www.wildfly.org/news/2022/08/19/RHOSAK/"&gt;Using RHOSAK from WildFly&lt;/a&gt;, by Kabir Khan&lt;/p&gt; &lt;p&gt;In this post Kabir shows how to write a simple application which sends and receives messages to/from a Kafka instance using &lt;strong&gt;RHOSAK&lt;/strong&gt;. RHOSAK - Red Hat OpenShift Streams for Apache Kafka, is a cloud service hosted by Red Hat which makes setting up, managing, and scaling Apache Kafka instances very easy&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_getting_started_with_atlasmap"&gt;Getting started with AtlasMap&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="http://www.mastertheboss.com/java/getting-started-with-atlasmap/"&gt;Getting started with AtlasMap&lt;/a&gt;, by Francesco Marchioni&lt;/p&gt; &lt;p&gt;In this article, Francesco shows the basics of the AtlasMap data mapping solution. He also covers the basic set up of the Web UI and how to use it to create a minimal mapping file. Finally, he discusses two simple ways to use AtlasMap in your Java projects.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_optimize_loops_with_long_variables_in_java"&gt;Optimize loops with long variables in Java&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/08/25/optimize-loops-long-variables-java#why_optimization_was_added_for_long_variables"&gt;Optimize loops with long variables in Java&lt;/a&gt;, by Roland Westrelin&lt;/p&gt; &lt;p&gt;The just-in-time (JIT) compiler in OpenJDK improves Java performance through a number of optimizations, particularly in loops. Until recently, many optimizations worked only when the loop index was an int variable. In this article, Roland shows how the HotSpot virtual machine was upgraded to add the same optimizations for long variables.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_a_dmn_feel_handbook"&gt;A DMN FEEL HANDBOOK&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://blog.kie.org/2022/08/a-dmn-feel-handbook.html"&gt;A DMN FEEL handbook&lt;/a&gt;, by Matteo Mortari&lt;/p&gt; &lt;p&gt;In this announcement, Matteo introduces an (experimental) DMN FEEL handbook, a helpful companion for your DMN modeling activities! You can access the FEEL handbook at &lt;a href="https://kiegroup.github.io/dmn-feel-handbook/#dmn-feel-handbook"&gt;DMN FEEL handbook&lt;/a&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_youtube_videos"&gt;YouTube videos&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;From unmissable demos to brilliant chat about the latest Java trends, the JBoss community has some great video content for you:&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=lLyVDqVK8cE"&gt;Quarkus Insights #99: Using Quarkus CodeStarts&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=7Q34Za79g18"&gt;Kubernetes Master Class - Avoiding configuration drift with Argo CD&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_see_you_next_time"&gt;See you next time&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;em&gt;Hope you enjoyed this edition. Please join us again in two weeks for our JBoss editorial!&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="author"&gt; &lt;pfe-avatar pfe-shape="circle" pfe-pattern="squares" pfe-src="/img/people/pedro-silva.png"&gt;&lt;/pfe-avatar&gt; &lt;span&gt;Pedro Silva&lt;/span&gt; &lt;/div&gt;&lt;/article&gt;</content><dc:creator>Pedro Silva</dc:creator></entry><entry><title>Move from apt to dnf package management</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/08/24/move-apt-dnf-package-management" /><author><name>Bob Reselman</name></author><id>7989058e-2a55-483d-926e-36cbd5eff3bf</id><updated>2022-08-24T07:00:00Z</updated><published>2022-08-24T07:00:00Z</published><summary type="html">&lt;p&gt;A package manager makes it simple to install &lt;a href="https://developers.redhat.com/topics/linux"&gt;GNU/Linux&lt;/a&gt; applications on a local computer. Before package management became commonplace, installing applications was a tedious, error-prone undertaking. The ease a package manager brings to installing an application on a Linux computer has been a major factor contributing to the widespread adoption of Linux as a mainstream operating system for both business and home users.&lt;/p&gt; &lt;p&gt;Package management under Linux is divided, however. Two major systems co-exist:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The APT package management system for Debian and its many derivatives, notably Ubuntu. Packages are marked with the &lt;code&gt;.deb&lt;/code&gt; suffix and are managed through the &lt;code&gt;apt&lt;/code&gt; command-line interface (CLI).&lt;/li&gt; &lt;li&gt;The RPM package management system for &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; and its derivatives, notably Fedora and CentOS Stream. Packages are marked with the &lt;code&gt;.rpm&lt;/code&gt; suffix and are managed through the &lt;code&gt;dnf&lt;/code&gt; CLI.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;This article is for developers who are currently using Debian-based systems and are familiar with APT, but want to start using a system in the Red Hat Enterprise Linux family. The article explains the similarities and differences between APT and RPM. I show how to execute specific, commonplace package management tasks using each system.&lt;/p&gt; &lt;h2&gt;Understanding apt, dnf, and yum&lt;/h2&gt; &lt;p&gt;Debian users are accustomed to managing their packages via the &lt;code&gt;apt&lt;/code&gt; command. Switching to the current RPM tool, &lt;code&gt;dnf&lt;/code&gt;, is the topic of this article.&lt;/p&gt; &lt;p&gt;You might also have seen references to a &lt;code&gt;yum&lt;/code&gt; command. Both &lt;code&gt;dnf&lt;/code&gt; and &lt;code&gt;yum&lt;/code&gt; are command-line utilities that work with RPM packages. Red Hat originally released and depended on &lt;code&gt;yum&lt;/code&gt;, which is an acronym for &lt;em&gt;Yellowdog Updater, Modified&lt;/em&gt;. &lt;code&gt;dnf&lt;/code&gt;, an abbreviation for &lt;em&gt;dandified yum&lt;/em&gt;, is the follow-up technology—based on &lt;code&gt;yum&lt;/code&gt;, as the name implies.&lt;/p&gt; &lt;p&gt;Today, &lt;code&gt;dnf&lt;/code&gt; is the default package management utility for Red Hat Enterprise Linux, Fedora, and CentOS Stream, and has been so since Fedora 22, CentOS 8, and Red Hat Enterprise Linux 8, respectively. &lt;code&gt;yum&lt;/code&gt; has been deprecated as the default package manager in the Red Hat family of distributions, so while &lt;code&gt;yum&lt;/code&gt; commands currently work, it's best to use just &lt;code&gt;dnf&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Understanding package discovery and installation&lt;/h2&gt; &lt;p&gt;The pattern for finding and installing a Linux package is essentially the same whether you're using &lt;code&gt;apt&lt;/code&gt; or &lt;code&gt;dnf&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;When you execute a command to install a package, the package manager looks at configuration files on the local machine to determine the location of a repository that has a given package on the internet. Then the installation command downloads the package along with its dependencies from the internet. Finally, the package manager installs and configures the application on the local machine. Figure 1 illustrates the process.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/patt.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/patt.png?itok=RGemPlHO" width="1111" height="602" alt="A package manager gets information from the local machine to retrieve a package from a repository." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: A package manager gets information from the local machine to retrieve a package from a repository. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;Although the basic installation process is similar for both the RPM and APT package managers, there are distinctions when it comes to implementation. Besides the commands used, there's a bit of difference in the way these commands consult files to find and install packages.&lt;/p&gt; &lt;p&gt;When you invoke a package manager's installation command, the package manager first looks to see whether the package of interest is present and already installed. APT looks in the &lt;code&gt;/var/cache/apt/archives&lt;/code&gt; directory for the presence of the package's &lt;code&gt;.deb&lt;/code&gt; file. Under RPM, the package manager inspects the directories in &lt;code&gt;/var/cache/dnf/&lt;/code&gt; for a package's &lt;code&gt;.rpm&lt;/code&gt; file.&lt;/p&gt; &lt;p&gt;If the package's &lt;code&gt;.deb&lt;/code&gt; or &lt;code&gt;.rpm&lt;/code&gt; file is not present, the installer inspects files that describe the locations of repositories on the internet. In some cases, these files can report the packages that are stored in a particular repository as well. Under APT, the information is stored in the file &lt;code&gt;/etc/apt/sources.list &lt;/code&gt;or in &lt;code&gt;.list&lt;/code&gt; files in the directory &lt;code&gt;/etc/apt/sources.list.d&lt;/code&gt;. Under RPM, repository details are stored in &lt;code&gt;.xml&lt;/code&gt; files or compressed &lt;code&gt;.solvx&lt;/code&gt; files in the cache directory &lt;code&gt;/var/cache/dnf/&lt;/code&gt;. Also, general information about a repository is stored in &lt;code&gt;.repo&lt;/code&gt; files in the directory &lt;code&gt;/etc/yum.repos.d&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;After discovering information about a package and repository, the installer goes to a remote repository to find and install the package. In some cases, the installer might have to go to a number of remote repositories looking for a package. Should the installer not find a package of interest, the package manager reports an error.&lt;/p&gt; &lt;p&gt;Thus, the overall pattern for package discovery and installation for APT and RPM is similar. The difference is in the CLI tools used. The structure and contents of the file system used by the package installer on the local computer differ as well.&lt;/p&gt; &lt;p&gt;Most users migrating from Debian's &lt;code&gt;apt&lt;/code&gt; to RPM's &lt;code&gt;dnf&lt;/code&gt; never have to concern themselves with the difference between the internals of the APT and RPM package managers. Low-level operations have been abstracted away by the CLI tools.&lt;/p&gt; &lt;h2&gt;Executing commonplace commands&lt;/h2&gt; &lt;p&gt;In most cases, the main concern of developers migrating from &lt;code&gt;apt&lt;/code&gt; to &lt;code&gt;dnf&lt;/code&gt; is installing, removing, and updating packages, which we'll cover in this section. But first, I'll show you how to add a repository to search and how to list packages and known repositories.&lt;/p&gt; &lt;h3&gt;Adding a repository for the package manager to search&lt;/h3&gt; &lt;p&gt;To install a package on your computer, the CLI tool needs to know where the repositories containing the packages are. Typically, when you first set up your computer, whether it's running an operating system from the Debian family or the Red Hat Enterprise Linux family, information about the basic repositories that host the usual packages for the given operating system is included in the OS by default. However, there might be times when you need to search other repositories. This section shows the commands for adding information about a repository to a local computer.&lt;/p&gt; &lt;p&gt;To add information about a repository to a computer running Debian, Ubuntu, etc., enter:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# add-apt-repository &lt;repository identification information&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For example, the following command installs information for the MongoDB database on a  Debian machine:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo add-apt-repository 'deb [arch=amd64] https://repo.mongodb.org/apt/ubuntu bionic/mongodb-org/4.0 multiverse'&lt;/code&gt;&lt;/pre&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: Commands that change system software must be entered as the superuser (root). Hence, these commands are prefixed with &lt;code&gt;sudo&lt;/code&gt;. I show the command prompt &lt;code&gt;#&lt;/code&gt; as a reminder that you must be running as root.&lt;/p&gt; &lt;p&gt;To add information about a repository to a computer running Red Hat Enterprise Linux, Fedora, or CentOS Stream, enter:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# dnf config-manager --add-repo &lt;repo_url&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following example installs the information about a mirror repository for CentOS 9 on the local machine:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo dnf config-manager --add-repo="https://mirror.aarnet.edu.au/pub/centos/9"&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Updating the repository&lt;/h3&gt; &lt;p&gt;You also want to routinely make sure that current packages on the host computer are up to date. To update existing packages on Debian, run the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo apt update&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To update existing packages on a computer in the Red Hat Enterprise Linux family, execute the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo dnf update&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Installing an application&lt;/h3&gt; &lt;p&gt;As mentioned previously, the pattern for installing packages on a host computer is similar in Debian and machines in the Red Hat Enterprise Linux family.&lt;/p&gt; &lt;p&gt;To install a package on a Debian machine, enter:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo apt install &lt;package_name&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following example installs the &lt;code&gt;jq&lt;/code&gt; utility for parsing and filtering JSON files on a Debian machine:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo apt install jq&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To install a package on a machine in the Red Hat Enterprise Linux family, enter:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo dnf install &lt;package_name&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following example installs the &lt;code&gt;jq&lt;/code&gt; utility on a machine in the Red Hat Enterprise Linux family:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo dnf install jq&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Removing an application&lt;/h3&gt; &lt;p&gt;The pattern for removing an application is similar for systems based on Debian and on Red Hat Enterprise Linux. The difference is the CLI tool used.&lt;/p&gt; &lt;p&gt;To remove a package on a Debian machine, enter:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo apt remove &lt;package_name&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following example removes the &lt;code&gt;jq&lt;/code&gt; utility from a Debian machine:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo apt remove jq&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To remove a package on Red Hat Enterprise Linux, enter:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo dnf remove &lt;package_name&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following example removes the &lt;code&gt;jq&lt;/code&gt; utility from a Red Hat Enterprise Linux machine:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo dnf remove jq&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Getting a list of packages installed on a host computer&lt;/h3&gt; &lt;p&gt;Listing the packages installed on a local machine can furnish useful information, particularly for auditing and system management.&lt;/p&gt; &lt;p&gt;To list all the packages installed on a machine running Debian, enter:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ apt list&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following example shows you how to use that command in conjunction with the &lt;code&gt;grep&lt;/code&gt; command to filter the results using a regular expression. The regular expression in this example saves only the lines that start with the characters &lt;code&gt;git&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ apt list | grep '^git'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following output shows a partial list of the results:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;git-annex-remote-rclone/focal,focal 0.6-1 all git-annex/focal 8.20200226-1 amd64 git-build-recipe/focal,focal 0.3.6 all git-buildpackage-rpm/focal,focal 0.9.19 all git-buildpackage/focal,focal 0.9.19 all git-cola/focal,focal 3.6-1 all git-crecord/focal,focal 20190217~git-1 all . . .&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To list the packages installed on a Red Hat Enterprise Linux machine, enter:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ dnf list installed&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following example shows how to use that command to get a list of packages installed on a Red Hat Enterprise Linux machine and then pick out lines that start with &lt;code&gt;git&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ dnf list installed | grep '^git' &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The command produces the following output:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;git.x86_64 2.35.3-1.fc35 @updates git-core.x86_64 2.35.3-1.fc35 @updates git-core-doc.noarch 2.35.3-1.fc35 @updates&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Getting a list of repositories known to a host computer&lt;/h3&gt; &lt;p&gt;Debian and the Red Hat Enterprise Linux family have different methods for listing repositories known to a given local computer.&lt;/p&gt; &lt;p&gt;Under a default installation of Debian, no single command has the logic to report known repositories. Instead, you have to finesse existing commands.&lt;/p&gt; &lt;p&gt;One way to list known repositories is to use the &lt;code&gt;apt-cache policy&lt;/code&gt; command to return the known repositories, as shown in the following example:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ apt-cache policy |grep http |awk '{print $2 " " $3}' |sort -u&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We have seen &lt;code&gt;grep&lt;/code&gt; already. The &lt;code&gt;awk&lt;/code&gt; command that follows in the pipeline selects the second and third words of each line. The full command produces the following output:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;http://dl.google.com/linux/chrome/deb stable/main http://ppa.launchpad.net/ansible/ansible/ubuntu focal/main http://security.ubuntu.com/ubuntu focal-security/main http://security.ubuntu.com/ubuntu focal-security/multiverse http://security.ubuntu.com/ubuntu focal-security/restricted http://security.ubuntu.com/ubuntu focal-security/universe http://us.archive.ubuntu.com/ubuntu focal-backports/main http://us.archive.ubuntu.com/ubuntu focal-backports/universe http://us.archive.ubuntu.com/ubuntu focal/main http://us.archive.ubuntu.com/ubuntu focal/multiverse http://us.archive.ubuntu.com/ubuntu focal/restricted http://us.archive.ubuntu.com/ubuntu focal/universe http://us.archive.ubuntu.com/ubuntu focal-updates/main http://us.archive.ubuntu.com/ubuntu focal-updates/multiverse http://us.archive.ubuntu.com/ubuntu focal-updates/restricted http://us.archive.ubuntu.com/ubuntu focal-updates/universe&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Another way to get a list of repositories is to inspect the entries that start with the characters &lt;code&gt;deb&lt;/code&gt; in the &lt;code&gt;etc/apt/sources.list&lt;/code&gt; files:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo grep -rhE ^deb /etc/apt/sources.list*&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The command produces the following output:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;deb http://us.archive.ubuntu.com/ubuntu/ focal main restricted deb http://us.archive.ubuntu.com/ubuntu/ focal-updates main restricted deb http://us.archive.ubuntu.com/ubuntu/ focal universe deb http://us.archive.ubuntu.com/ubuntu/ focal-updates universe deb http://us.archive.ubuntu.com/ubuntu/ focal multiverse&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Things are easier when using &lt;code&gt;dnf&lt;/code&gt; in the Red Hat Enterprise Linux family. The &lt;code&gt;dnf repolist&lt;/code&gt; command lists the repositories known to the local machine.&lt;/p&gt; &lt;p&gt;The following example shows the result of running the &lt;code&gt;dnf repolist&lt;/code&gt; command. By default the command displays the two columns, &lt;code&gt;repo id&lt;/code&gt; and &lt;code&gt;repo name&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ dnf repolist&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The command produces the following output:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;repo id repo name fedora Fedora 35 - x86_64 fedora-cisco-openh264 Fedora 35 openh264 (From Cisco) - x86_64 fedora-modular Fedora Modular 35 - x86_64 updates Fedora 35 - x86_64 - Updates updates-modular Fedora Modular 35 - x86_64 - Updates&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;A powerful and simple package management system&lt;/h2&gt; &lt;p&gt;Moving from Debian or Ubuntu to Red Hat Enterprise Linux, Fedora, or CentOS Stream requires some adjustment when it comes to working at the command line, but the transition can be easy.&lt;/p&gt; &lt;p&gt;The patterns for installing and removing applications are surprisingly similar, yet the command line tools are different. Ubuntu/Debian uses &lt;code&gt;apt&lt;/code&gt;. The Red Hat Enterprise Linux family uses &lt;code&gt;dnf&lt;/code&gt;. Both command line tools support similar subcommands, which is most evident with &lt;code&gt;apt install&lt;/code&gt; and &lt;code&gt;dnf install&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The techniques for keeping track of known repositories differ between operating systems. Fortunately for those moving to the Red Hat Enterprise Linux family, listing repositories is a lot easier because it involves only the &lt;code&gt;dnf repolist&lt;/code&gt; command. Listing repositories under Debian requires more work.&lt;/p&gt; &lt;p&gt;Learning the details of a new technology takes time. When transitioning from &lt;code&gt;apt&lt;/code&gt; to &lt;code&gt;dnf&lt;/code&gt;, you'll have to anticipate a learning curve. But the learning curve is not steep and you'll be up and running in no time.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/08/24/move-apt-dnf-package-management" title="Move from apt to dnf package management"&gt;Move from apt to dnf package management&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Bob Reselman</dc:creator><dc:date>2022-08-24T07:00:00Z</dc:date></entry><entry><title type="html">Quarkus 2.11.3.Final released - Fix for CVE-2022-2466 and other bugfixes</title><link rel="alternate" href="https://quarkus.io/blog/quarkus-2-11-3-final-released/" /><author><name>Guillaume Smet</name></author><id>https://quarkus.io/blog/quarkus-2-11-3-final-released/</id><updated>2022-08-24T00:00:00Z</updated><content type="html">2.11.3.Final is our third maintenance release for the 2.11 release train. It is a safe upgrade for anyone using 2.11. Among other issues, it fixes CVE-2022-2466 that was affected our quarkus-smallrye-graphql extension. Migration Guide If you are not already using 2.11, please refer to our migration guide. Full changelog You...</content><dc:creator>Guillaume Smet</dc:creator></entry><entry><title>How to use OpenTelemetry to trace Node.js applications</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/08/23/how-use-opentelemetry-trace-nodejs-applications" /><author><name>Annapurna Patil, Helio Frota, Rashmi Panchamukhi</name></author><id>090eca54-e9bd-4533-b223-1db3ca7060a3</id><updated>2022-08-23T07:00:00Z</updated><published>2022-08-23T07:00:00Z</published><summary type="html">&lt;p&gt;One great thing about &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js&lt;/a&gt; is how well it performs inside a container. The shift to &lt;a href="https://developers.redhat.com/topics/containers"&gt;containerized deployments and environments&lt;/a&gt; comes with extra complexity. This article addresses the added complexity of observability—seeing what's going on within your application and its resources. We will also cover how to set up &lt;a href="https://opentelemetry.io/"&gt;OpenTelemetry&lt;/a&gt; to achieve this visibility. This is useful when resource usage wanders outside of the expected norms.&lt;/p&gt; &lt;p&gt;The &lt;a href="https://www.cncf.io"&gt;Cloud Native Computing Foundation&lt;/a&gt; (CNCF) maintains a set of open source libraries and tools for visibility. OpenTelemetry is gaining momentum with developers to increase the observability of their Node.js applications through cross-component traces. OpenTelemetry with &lt;a href="https://www.jaegertracing.io/"&gt;Jaeger&lt;/a&gt; as a backend is a great option for tracing Node.js applications running inside of a container. Although OpenTelemetry is still in an incubated status at the CNCF, it is the leading choice for tracing. You can read more about why we believe in the importance of distributed tracing on the &lt;a href="https://github.com/nodeshift/nodejs-reference-architecture/blob/main/docs/operations/distributed-tracing.md"&gt;distributed tracing Node.js Reference Architecture page&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;This article demonstrates a scenario that illustrates how the lack of integration tests can lead to the appearance of an error in production. We investigate the error on a &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt; platform using OpenTelemetry traces to quickly answer the following questions:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Where is the problem?&lt;/li&gt; &lt;li&gt;What is causing the error?&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Follow this 5-step demonstration to troubleshoot production errors:&lt;/p&gt; &lt;h2&gt;Step 1.  Set up prerequisites&lt;/h2&gt; &lt;p&gt;Following the steps in this article, requires an OpenShift cluster with the &lt;a href="https://docs.openshift.com/container-platform/4.10/distr_tracing/distr_tracing_install/distr-tracing-deploying-jaeger.html"&gt;OpenShift distributed tracing platform Operator&lt;/a&gt; and &lt;a href="https://docs.openshift.com/container-platform/4.10/distr_tracing/distr_tracing_install/distr-tracing-deploying-otel.html"&gt;OpenShift distributed tracing data collection Operator (Technology Preview)&lt;/a&gt; installed.&lt;/p&gt; &lt;p&gt;We are using &lt;a href="https://developers.redhat.com/products/openshift-local/overview"&gt;OpenShift Local&lt;/a&gt; (formerly called Red Hat CodeReady Containers), which allows us to run a single-node OpenShift cluster locally. It doesn't have all the features of an OpenShift cluster. But OpenShift Local has everything we need for this article, and it's a good way to get started with OpenShift.&lt;/p&gt; &lt;p&gt;If you are going to use OpenShift Local, you can log in as &lt;code&gt;kubeadmin&lt;/code&gt; and install the Operators via &lt;a href="https://docs.openshift.com/container-platform/4.10/distr_tracing/distr_tracing_install/distr-tracing-installing.html"&gt;OperatorHub&lt;/a&gt; (Figure 1). If you work on an OpenShift cluster set up by an organization, ask the cluster administrator to install the Operators.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/Trace-nodejs-image1.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/Trace-nodejs-image1.png?itok=YloMk8qm" width="600" height="252" alt="A screenshot of the OperatorHub page" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: The OpenShift distributed tracing data collection Operator can be installed from the OperatorHub page shown in this screenshot. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;h2&gt;Step 2. Run the CRUD application example&lt;/h2&gt; &lt;p&gt;For this demonstration, we will use the &lt;a href="https://github.com/nodeshift-starters/nodejs-rest-http-crud"&gt;Nodeshift RESTful HTTP CRUD starter application&lt;/a&gt;. Clone this GitHub repository from the command line:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ git clone https://github.com/nodeshift-starters/nodejs-rest-http-crud.git&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Navigate to the &lt;code&gt;nodejs-rest-http-crud&lt;/code&gt; directory of the cloned repository:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cd nodejs-rest-http-crud&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Make sure you are logged into your OpenShift cluster as a developer, using &lt;code&gt;oc login&lt;/code&gt;. Create a new project called &lt;code&gt;opentel&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc new-project opentel&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;nodejs-rest-http-crud&lt;/code&gt; example requires a PostgreSQL database. So install a Postgres db into your OpenShift cluster:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc new-app -e POSTGRESQL_USER=luke -e POSTGRESQL_PASSWORD=secret -e POSTGRESQL_DATABASE=my_data centos/postgresql-10-centos7 --name=my-database&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Step 3. Set up the Node.js program for tracing&lt;/h2&gt; &lt;p&gt;We are going to add a bug deliberately to the Node.js program so you can simulate the process of tracing a problem. Open the &lt;code&gt;lib/api/fruits.js&lt;/code&gt; file and change the SQL statement in the &lt;code&gt;create&lt;/code&gt; function from &lt;code&gt;INSERT INTO products&lt;/code&gt; to &lt;code&gt;INSERT INTO product0&lt;/code&gt;. Changing the last character to zero makes the statement query a nonexistent database table.&lt;/p&gt; &lt;p&gt;Now deploy the example:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ npm run openshift&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Once it's deployed, you should see the application and the database running in the developer topology view (Figure 2).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/Trace-nodejs-Fig2.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/Trace-nodejs-Fig2.png?itok=_fPgYBJX" width="600" height="373" alt="The developer topology view of the application and the database." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: The topology view shows two circles, one for the Node.js application and one for the database. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;p&gt;The application exposes an endpoint that you can find by selecting the application and scrolling down to the &lt;strong&gt;Routes&lt;/strong&gt; section (Figure 3).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/Trace-nodejs-fig3.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/Trace-nodejs-fig3.png?itok=HtJ3878u" width="600" height="296" alt="A red arrow pointing to the endpoint under the routes section." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: The route that allows access to the application can be found by clicking on the application in the topology view. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;p&gt;However, if you go to that page and try to add a fruit, the operation will fail and trigger a notification alert (see Figure 4). This error alert appears because the application has a typo inserted on the database table name. It should be &lt;code&gt;products&lt;/code&gt; instead of &lt;code&gt;product0&lt;/code&gt;.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/Trace-nodejs-fig4.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/Trace-nodejs-fig4.png?itok=x15v-Gyi" width="600" height="345" alt="A screenshot of an invalid SQL statement alert." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: An alert appears in the UI when an invalid SQL statement is issued. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;p&gt;Check the &lt;code&gt;lib/api/fruits.js&lt;/code&gt; file within the project you cloned. If you are using an IDE, note that the spell check cannot highlight the error (Figure 5).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/Trace-nodejs-fig5.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/Trace-nodejs-fig5.png?itok=UhDh4tyJ" width="600" height="58" alt="IDE does not flag a character 0 error in the code shown." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: There's an error in the code, but the IDE does not flag this particular error with a character 0. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;p&gt;In other situations, the IDE will highlight a misspelled word (shown in Figure 6).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/Trace-nodejs-fig6.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/Trace-nodejs-fig6.png?itok=ElGKKnID" width="600" height="61" alt="The IDE highlights a spelling error in the code." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 6: The IDE highlights an error such as an extraneous letter in the table name. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;p&gt;The typo we introduced would likely have been caught by integration tests. But the problem preventing the program from running is an example of something that can happen in production resulting from a lack of test coverage. In cases like these, tracing can not only identify the component where the error occurred but also identify the exact problem.&lt;/p&gt; &lt;h2&gt;Step 4. Instrument the production application&lt;/h2&gt; &lt;p&gt;Now you can instrument your application to quickly identify what is happening. Normally you would already have your production application instrumented, but we are demonstrating this example step by step.&lt;/p&gt; &lt;p&gt;To instrument the application:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Add a number of OpenTelemetry dependencies to the &lt;code&gt;package.json&lt;/code&gt; file.&lt;/li&gt; &lt;li&gt;Create a file named &lt;code&gt;tracer.js&lt;/code&gt;  that will inject OpenTelemetry into the application.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;We will detail these two tasks in the following subsections:&lt;/p&gt; &lt;h3&gt;Add OpenTelemetry dependencies&lt;/h3&gt; &lt;p&gt;The following list shows the dependencies we added. You may want to use newer versions, depending on when you are reading this article:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-json"&gt;"@opentelemetry/api": "^1.1.0", "@opentelemetry/exporter-jaeger": "^1.3.1", "@opentelemetry/exporter-trace-otlp-http": "^0.29.2", "@opentelemetry/instrumentation": "^0.29.2", "@opentelemetry/instrumentation-express": "^0.30.0", "@opentelemetry/instrumentation-http": "^0.29.2", "@opentelemetry/instrumentation-pg": "^0.30.0", "@opentelemetry/resources": "^1.3.1", "@opentelemetry/sdk-node": "^0.29.2", "@opentelemetry/sdk-trace-base": "^1.3.1", "@opentelemetry/sdk-trace-node": "^1.3.1", "@opentelemetry/semantic-conventions": "^1.3.1", &lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Create the tracer.js file&lt;/h3&gt; &lt;p&gt;The content of the &lt;code&gt;tracer.js&lt;/code&gt; file is:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-javascript"&gt;'use strict'; const { diag, DiagConsoleLogger, DiagLogLevel } = require('@opentelemetry/api'); // SDK const opentelemetry = require('@opentelemetry/sdk-node'); // Express, postgres and http instrumentation const { NodeTracerProvider } = require('@opentelemetry/sdk-trace-node'); const { registerInstrumentations } = require('@opentelemetry/instrumentation'); const { HttpInstrumentation } = require('@opentelemetry/instrumentation-http'); const { ExpressInstrumentation } = require('@opentelemetry/instrumentation-express'); const { PgInstrumentation } = require('@opentelemetry/instrumentation-pg'); // Collector trace exporter const { Resource } = require('@opentelemetry/resources'); const { SemanticResourceAttributes } = require('@opentelemetry/semantic-conventions'); const { SimpleSpanProcessor } = require('@opentelemetry/sdk-trace-base'); const { OTLPTraceExporter } = require('@opentelemetry/exporter-trace-otlp-http'); diag.setLogger(new DiagConsoleLogger(), DiagLogLevel.DEBUG); // Tracer provider const provider = new NodeTracerProvider({ resource: new Resource({ [SemanticResourceAttributes.SERVICE_NAME]: 'fruits' }) }); registerInstrumentations({ instrumentations: [ // Currently to be able to have auto-instrumentation for express // We need the auto-instrumentation for HTTP. new HttpInstrumentation(), new ExpressInstrumentation(), new PgInstrumentation() ] }); // Tracer exporter const traceExporter = new OTLPTraceExporter({ url: 'http://opentel-collector-headless.opentel.svc:4318/v1/traces' }); provider.addSpanProcessor(new SimpleSpanProcessor(traceExporter)); provider.register(); // SDK configuration and start up const sdk = new opentelemetry.NodeSDK({ traceExporter }); (async () =&gt; { try { await sdk.start(); console.log('Tracing started.'); } catch (error) { console.error(error); } })(); // For local development to stop the tracing using Control+c process.on('SIGINT', async () =&gt; { try { await sdk.shutdown(); console.log('Tracing finished.'); } catch (error) { console.error(error); } finally { process.exit(0); } }); &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Don't worry, you don't need to change the core business code to make it work. You would just require &lt;code&gt;tracer.js&lt;/code&gt; at the top of the &lt;code&gt;app.js&lt;/code&gt; file. But we have already coded that line here. Now you only need to uncomment the &lt;code&gt;require('./tracer');&lt;/code&gt; line in our example.&lt;/p&gt; &lt;p&gt;This &lt;code&gt;tracer.js&lt;/code&gt; file is composed of several parts that refer to the plugins we are using. You could adapt the file for your specific needs. The following documentation provides more information:&lt;/p&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.npmjs.com/package/@opentelemetry/exporter-trace-otlp-http"&gt;OpenTelemetry Collector Exporter for web and node&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.npmjs.com/package/@opentelemetry/instrumentation-pg"&gt;OpenTelemetry Postgres Instrumentation for Node.js&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.npmjs.com/package/@opentelemetry/instrumentation-express"&gt;OpenTelemetry Express Instrumentation for Node.js&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.npmjs.com/package/@opentelemetry/instrumentation-http"&gt;OpenTelemetry HTTP and HTTPS Instrumentation for Node.js&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.npmjs.com/package/@opentelemetry/semantic-conventions"&gt;OpenTelemetry Semantic Conventions&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.npmjs.com/package/@opentelemetry/sdk-trace-node"&gt;OpenTelemetry Node SDK&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Step 5. Trace with OpenTelemetry&lt;/h2&gt; &lt;p&gt;In this section, we will debug OpenTelemetry. This helps us troubleshoot our &lt;code&gt;tracer.js&lt;/code&gt; code.&lt;/p&gt; &lt;ul&gt; &lt;li&gt; &lt;h3&gt;Set up the trace as follows:&lt;/h3&gt; &lt;/li&gt; &lt;/ul&gt; &lt;pre&gt; &lt;code&gt;const { diag, DiagConsoleLogger, DiagLogLevel } = require('@opentelemetry/api'); diag.setLogger(new DiagConsoleLogger(), DiagLogLevel.DEBUG);&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Then create a new resource for &lt;code&gt;NodeTracerProvider&lt;/code&gt; to help identify our service inside Jaeger. In this case, we use the service name, &lt;code&gt;fruits&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;const provider = new NodeTracerProvider({ resource: new Resource({ [SemanticResourceAttributes.SERVICE_NAME]: 'fruits' }) });&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Because this is an &lt;a href="https://www.npmjs.com/package/express"&gt;Express&lt;/a&gt; application that also uses PostgreSQL, we want to trace those layers. We also need to register &lt;code&gt;HttpInstrumentation&lt;/code&gt; to make &lt;code&gt;ExpressInstrumentation&lt;/code&gt; work.&lt;/p&gt; &lt;ul&gt; &lt;li&gt; &lt;h3&gt;Register the instrumentation:&lt;/h3&gt; &lt;/li&gt; &lt;/ul&gt; &lt;pre&gt; &lt;code&gt;registerInstrumentations({ instrumentations: [ new HttpInstrumentation(), new ExpressInstrumentation(), new PgInstrumentation() ] });&lt;/code&gt;&lt;/pre&gt; &lt;ul&gt; &lt;li&gt; &lt;h3&gt;Create the following trace exporter:&lt;/h3&gt; &lt;/li&gt; &lt;/ul&gt; &lt;pre&gt; &lt;code&gt;const traceExporter = new OTLPTraceExporter({ url: 'http://opentel-collector-headless.opentel.svc:4318/v1/traces' });&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can add an environment variable if you need to specify a different URL for the OpenTelemetry Collector.&lt;/p&gt; &lt;ul&gt; &lt;li&gt; &lt;h3&gt;Install Jaeger and OpenTelemetry Collector&lt;/h3&gt; &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;To continue this configuration, we need to give user admin rights on the &lt;code&gt;opentel&lt;/code&gt; project to the developer to successfully install both the Jaeger and OpenTelemetry Collector Operators.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc policy add-role-to-user admin developer -n opentel&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Create and apply a Jaeger custom resource:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc apply -f tracing/jaeger.yml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Create an OpenTelemetryCollector custom resource:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc apply -f tracing/opentel-collector.yml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Inside OpenShift, the topology menu now shows the components (Figure 7).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/Trace-nodejs-fig7.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/Trace-nodejs-fig7.png?itok=dHq75w87" width="600" height="331" alt="OpenShift topology menu showing OpenTelemetry and Jaeger components." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 7: OpenTelemetry and Jaeger components appear in the topology view. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;p&gt;We have installed the Collector along with the auto-instrumentation plugins installed when we added &lt;code&gt;tracer.js&lt;/code&gt; to &lt;code&gt;app.js&lt;/code&gt;. Now, these plugins will catch and send the traces to the Collector instance in our namespace. The Collector will receive, process, and export them to the Jaeger instance in our namespace.&lt;/p&gt; &lt;ul&gt; &lt;li&gt; &lt;h3&gt;Check the traces:&lt;/h3&gt; &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Go back to the application and try to add a new fruit again. You will still get the same error, but traces of additional information now appear in the Jaeger UI.&lt;/p&gt; &lt;p&gt;To view these traces, click on the Jaeger link icon in the topology. The icon is a little box with an outgoing arrow (Figure 8). You might have to log in again the first time you check the traces.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/Trace-nodejs-fig8.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/Trace-nodejs-fig8.png?itok=Wi3se1IX" width="600" height="288" alt="An arrow points to the Jaeger link icon in the topology view." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 8: Traces are available for a component when a small box icon appears at the top right of the component. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;p&gt;The icon takes you to the Jaeger UI (Figure 9), where you can filter traces based on the service called &lt;code&gt;fruits&lt;/code&gt; (set in our  &lt;code&gt;tracer.js &lt;/code&gt;configuration) and identify the error:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Enter &lt;code&gt;fruits&lt;/code&gt; in the &lt;strong&gt;Service&lt;/strong&gt; box.&lt;/li&gt; &lt;li&gt;Enter &lt;code&gt;POST /api/fruits &lt;/code&gt;in the &lt;strong&gt;Operation&lt;/strong&gt; box.&lt;/li&gt; &lt;li&gt;Select the &lt;strong&gt;Find traces&lt;/strong&gt; button.&lt;/li&gt; &lt;/ul&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/Trace-nodejs-fig9.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/Trace-nodejs-fig9.png?itok=Fo8i0Lit" width="600" height="334" alt="Illustration of the Jaeger form." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 9: Fill out Jaeger's form as described in the text. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;p&gt;Click on the error trace to view all the operations passing through Express and its middleware up to the database (Figure 10).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/Trace-nodejs-fig10.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/Trace-nodejs-fig10.png?itok=W7ZiSzlk" width="600" height="294" alt="The Jaeger UI shows a history of operations after clicking the error trace." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 10: Jaeger shows everything that happened up until the call reaches the database. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;p&gt;Click on the error to view more specific details (Figure 11).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/Trace-nodejs-fig11.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/Trace-nodejs-fig11.png?itok=OO_mqs80" width="600" height="242" alt="A screenshot of a list of details about an error." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 11: Error details include a cause statement and the error message. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;p&gt;Jaeger provides the SQL statement. Here you can double-check the code and the error message on the &lt;code&gt;otel.status_description&lt;/code&gt; line: "relation 'product0' does not exist."&lt;/p&gt; &lt;p&gt;This information reveals that, although the error was reported from the database component, the problem springs from the application, which specified a table that does not exist. This information allows you to go back to the application and fix the bug.&lt;/p&gt; &lt;p&gt;Although this example is a bit contrived, it illustrates the level of information provided by auto-instrumentation, as well as the power of connecting the information provided with the flow of the request through the application's components.&lt;/p&gt; &lt;p&gt;Another benefit of OpenTelemetry is that the same trace for the &lt;code&gt;/api/fruits&lt;/code&gt; request shows the time spent in the &lt;code&gt;pg:query:select&lt;/code&gt; step. If this step creates a performance problem, you might be able to resolve it by adding an additional index to the products table.&lt;/p&gt; &lt;h2&gt;OpenTelemetry benefits networked applications&lt;/h2&gt; &lt;p&gt;This article illustrated how OpenTelemetry tracing increases observability for a Node.js deployment in OpenShift. The &lt;code&gt;tracer.js&lt;/code&gt; example demonstrated:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;That operators provided by Red Hat were easily installed in OpenShift, creating individual OpenTelemetry Collector and Jaeger instances for an application.&lt;/li&gt; &lt;li&gt;The addition of auto-instrumentation plugins for common &lt;a href="https://github.com/open-telemetry/opentelemetry-js-contrib/tree/main/plugins/node"&gt;Node.js packages&lt;/a&gt; to an existing Node.js application.&lt;/li&gt; &lt;li&gt;The captured traces answered two key questions: Where is the problem and what is causing the error? In our example, the answers were: The problem was located in the database layer source code and a typo in an SQL statement caused that bug.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Has this piqued your interest in trying OpenTelemetry in your environment? We hope this article has helped you understand how you to use OpenTelemetry with a Node.js application deployed to OpenShift.&lt;/p&gt; &lt;p&gt;Read more about &lt;a href="https://www.ibm.com/cloud/learn/observability"&gt;observability&lt;/a&gt;, &lt;a href="https://docs.openshift.com/container-platform/4.10/distr_tracing/distributed-tracing-release-notes.html#distr-tracing-product-overview_distributed-tracing-release-notes"&gt;Red Hat distributed tracing&lt;/a&gt;, and &lt;a href="https://opentelemetry.io/docs/instrumentation/js/"&gt;OpenTelemetry&lt;/a&gt;. To learn more about what Red Hat is up to on the Node.js front, check out our &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js topic page&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/08/23/how-use-opentelemetry-trace-nodejs-applications" title="How to use OpenTelemetry to trace Node.js applications"&gt;How to use OpenTelemetry to trace Node.js applications&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Annapurna Patil, Helio Frota, Rashmi Panchamukhi</dc:creator><dc:date>2022-08-23T07:00:00Z</dc:date></entry></feed>
